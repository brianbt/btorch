{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/brianbt/btorch\n!pip install transformers\n!pip install pip install datasets","metadata":{"id":"KuHpQ3H4UmcP","outputId":"e24d50bc-c7e7-452b-9e3b-bba7fe025a89","execution":{"iopub.status.busy":"2022-07-06T04:24:40.723831Z","iopub.execute_input":"2022-07-06T04:24:40.724142Z","iopub.status.idle":"2022-07-06T04:25:19.587404Z","shell.execute_reply.started":"2022-07-06T04:24:40.724066Z","shell.execute_reply":"2022-07-06T04:25:19.586262Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/brianbt/btorch\n  Cloning https://github.com/brianbt/btorch to /tmp/pip-req-build-5a9bzyx6\n  Running command git clone --filter=blob:none --quiet https://github.com/brianbt/btorch /tmp/pip-req-build-5a9bzyx6\n  Resolved https://github.com/brianbt/btorch to commit 467981f6eeb0f504330c83727217faeac680702f\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (0.12.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.3.5)\nCollecting torchinfo\n  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (4.5.4.60)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.0.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (3.5.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (4.64.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.7.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (0.11.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (1.4.2)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (4.33.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (9.1.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (21.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->btorch==0.0.1) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->btorch==0.0.1) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->btorch==0.0.1) (3.1.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->btorch==0.0.1) (4.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->btorch==0.0.1) (2.27.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->btorch==0.0.1) (1.16.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (2.0.12)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (2022.6.15)\nBuilding wheels for collected packages: btorch\n  Building wheel for btorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for btorch: filename=btorch-0.0.1-py3-none-any.whl size=53134 sha256=6111a7d76506aa8b3414751f0e9f236db52cd2d228848ce2f66e7ce764348e57\n  Stored in directory: /tmp/pip-ephem-wheel-cache-_xb602ko/wheels/fa/ef/1e/1248ce8683f1b6fd8e6552260da8c1dcfbb352d899fef03d72\nSuccessfully built btorch\nInstalling collected packages: torchinfo, btorch\nSuccessfully installed btorch-0.0.1 torchinfo-1.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.18.0)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.7.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.53)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.1.1)\nCollecting install\n  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.5.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.7.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.27.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.12)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\nInstalling collected packages: install\nSuccessfully installed install-1.3.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{"id":"R-b4AZoFZcX4"}},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\n\n# Btorch\nimport btorch\nfrom btorch import nn\nimport btorch.nn.functional as F\n\n# Hugging Face\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel","metadata":{"id":"BRBNaal2UwIC","execution":{"iopub.status.busy":"2022-07-06T04:25:19.589689Z","iopub.execute_input":"2022-07-06T04:25:19.590311Z","iopub.status.idle":"2022-07-06T04:25:26.482395Z","shell.execute_reply.started":"2022-07-06T04:25:19.590270Z","shell.execute_reply":"2022-07-06T04:25:26.481460Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{"id":"8c8Kv2NIZaA7"}},{"cell_type":"code","source":"# https://huggingface.co/datasets/emotion\n# this dataset have 6 classes\nidx2label = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n\ndataset = load_dataset(\"emotion\")\nprint(dataset)\n# Lets check how one datapoint looks like\nprint(next(iter(dataset['train'])))","metadata":{"id":"WGfSENxsWtRj","outputId":"77216628-6396-4269-bb72-b193d1367792","execution":{"iopub.status.busy":"2022-07-06T04:25:26.483819Z","iopub.execute_input":"2022-07-06T04:25:26.484449Z","iopub.status.idle":"2022-07-06T04:25:55.576829Z","shell.execute_reply.started":"2022-07-06T04:25:26.484413Z","shell.execute_reply":"2022-07-06T04:25:55.575677Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"800866d432394cb0a375f4343817b29d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7784d16f3de8478088f674ff06a3e222"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e9bacdd73c4840b5bb38f44ff3aa7db4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/204k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10558c18e03d4171b70919761dd1c434"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd1d4012efe34ef19af393915a845281"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd0e07e5234d48fd8ec67f873da65d13"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})\n{'text': 'i didnt feel humiliated', 'label': 0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create HuggingFace BERT 🤗 ","metadata":{"id":"J3XLAdmZZd6U"}},{"cell_type":"code","source":"#https://huggingface.co/bert-base-uncased\nmodel_name = 'bert-base-uncased'\n\n# You can check the config parameter options from the below links\n#https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/configuration#transformers.PretrainedConfig\n#https://huggingface.co/docs/transformers/v4.20.1/en/model_doc/bert#transformers.BertConfig\nconfig = AutoConfig.from_pretrained(\n    model_name, \n    output_hidden_states = True,\n    output_attention = True,\n    hidden_dropout_prob = 0.2,\n) \nprint(config)\n\n# Use above config to create our BERT model\npretrain_model = AutoModel.from_pretrained(\n    model_name,\n    config = config\n)\n\n# Create a BERT tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"id":"O5tU8u94VTOe","outputId":"3c319b4f-ec64-4b00-ce3e-6d442c318665","execution":{"iopub.status.busy":"2022-07-06T04:25:55.579716Z","iopub.execute_input":"2022-07-06T04:25:55.580640Z","iopub.status.idle":"2022-07-06T04:26:55.621171Z","shell.execute_reply.started":"2022-07-06T04:25:55.580584Z","shell.execute_reply":"2022-07-06T04:26:55.620185Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7113a4d53cec4eceb8e966a3676ba6ba"}},"metadata":{}},{"name":"stdout","text":"BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.2,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8902568725144b0d95be351c6b9837c8"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e78d4ad81e4a089661073b9dd0e98e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"00469ab034a54f3c8cabf32dfb44573e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"45a52889051143a98a89273b45bcc1d2"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Quick tutor for tokenizer usgage","metadata":{"id":"T08jXqOjZuVh"}},{"cell_type":"code","source":"x = ['i didnt feel humiliated',\n     'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n     'im grabbing a minute to post i feel greedy wrong']\ny = [0,\n     0,\n     3]","metadata":{"id":"pAfrw0bcZxnW","execution":{"iopub.status.busy":"2022-07-06T04:26:55.622847Z","iopub.execute_input":"2022-07-06T04:26:55.623217Z","iopub.status.idle":"2022-07-06T04:26:55.628374Z","shell.execute_reply.started":"2022-07-06T04:26:55.623179Z","shell.execute_reply":"2022-07-06T04:26:55.627276Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Since each data in one batch must have same size. We do padding and truncation such that the length is 10 for each sentence.\n# The padding idx will be ``0``\n# Tokenizer will append [CLS] and [SEP] in front and at back of the sentence.\n# Then add [PAD] to make the entire length=max_length\ntokens = tokenizer(x, padding=True, truncation=True, max_length=10)\ndisplay(tokens['input_ids'])\n","metadata":{"id":"Gb89owk5Z4f_","outputId":"447a7d2a-25d4-443f-e79f-18bfbaa4837a","execution":{"iopub.status.busy":"2022-07-06T04:56:44.555203Z","iopub.execute_input":"2022-07-06T04:56:44.555573Z","iopub.status.idle":"2022-07-06T04:56:44.565656Z","shell.execute_reply.started":"2022-07-06T04:56:44.555541Z","shell.execute_reply":"2022-07-06T04:56:44.564672Z"},"trusted":true},"execution_count":115,"outputs":[{"output_type":"display_data","data":{"text/plain":"[[101, 1045, 2572, 6517, 102, 0, 0, 0, 0, 0],\n [101, 1045, 2572, 3407, 102, 0, 0, 0, 0, 0],\n [101, 1045, 3030, 3110, 3147, 1998, 2211, 3110, 2980, 102],\n [101, 2054, 1996, 17752, 2003, 2023, 102, 0, 0, 0],\n [101, 1045, 2123, 1005, 1056, 2729, 2054, 2017, 2079, 102],\n [101, 1045, 2293, 2017, 11910, 102, 0, 0, 0, 0],\n [101, 1045, 2293, 2017, 1999, 2296, 5304, 102, 0, 0]]"},"metadata":{}}]},{"cell_type":"code","source":"# Lets decode thosse index\n[tokenizer.decode(i, padding=True, truncation=True, max_length=50) for i in tokens['input_ids']]","metadata":{"execution":{"iopub.status.busy":"2022-07-06T04:56:45.205030Z","iopub.execute_input":"2022-07-06T04:56:45.205398Z","iopub.status.idle":"2022-07-06T04:56:45.213285Z","shell.execute_reply.started":"2022-07-06T04:56:45.205367Z","shell.execute_reply":"2022-07-06T04:56:45.212228Z"},"trusted":true},"execution_count":116,"outputs":[{"execution_count":116,"output_type":"execute_result","data":{"text/plain":"['[CLS] i am sad [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] i am happy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] i stopped feeling cold and began feeling hot [SEP]',\n '[CLS] what the heck is this [SEP] [PAD] [PAD] [PAD]',\n \"[CLS] i don't care what you do [SEP]\",\n '[CLS] i love you 3000 [SEP] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] i love you in every universe [SEP] [PAD] [PAD]']"},"metadata":{}}]},{"cell_type":"code","source":"# This is either 0 or 1.\n# Remeber training data for BERT have two parts. \n# The first is indicated as 0, the second is indicated as 1\ndisplay(tokens['token_type_ids'])","metadata":{"id":"iimxfodiaV7R","outputId":"c6d218a5-e0fc-4560-a3aa-76d795a61229","execution":{"iopub.status.busy":"2022-07-06T04:56:48.363707Z","iopub.execute_input":"2022-07-06T04:56:48.364281Z","iopub.status.idle":"2022-07-06T04:56:48.371907Z","shell.execute_reply.started":"2022-07-06T04:56:48.364237Z","shell.execute_reply":"2022-07-06T04:56:48.370919Z"},"trusted":true},"execution_count":117,"outputs":[{"output_type":"display_data","data":{"text/plain":"[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"},"metadata":{}}]},{"cell_type":"code","source":"# This is attention mask.\n# 0 means attention should be see those words\n# Becoz those words is padded\ndisplay(tokens['attention_mask'])","metadata":{"id":"dt4XMSifbOn0","outputId":"016bdb74-d843-4ef2-a4bf-0e86a623dbed","execution":{"iopub.status.busy":"2022-07-06T04:56:48.748435Z","iopub.execute_input":"2022-07-06T04:56:48.748814Z","iopub.status.idle":"2022-07-06T04:56:48.756978Z","shell.execute_reply.started":"2022-07-06T04:56:48.748783Z","shell.execute_reply":"2022-07-06T04:56:48.755811Z"},"trusted":true},"execution_count":118,"outputs":[{"output_type":"display_data","data":{"text/plain":"[[1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n [1, 1, 1, 1, 1, 1, 1, 1, 0, 0]]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Quick tutor for BERT usgage","metadata":{"id":"MrIsIzIjb-62"}},{"cell_type":"code","source":"# here (N,T) is (3, max_length=10)\ninputs = torch.tensor(tokens['input_ids'])\nattn_masks = torch.tensor(tokens['attention_mask'])\n# Hugging Face BERT will produce three thing for us base on how we set the config\nout = pretrain_model(inputs, attention_mask=attn_masks)\nprint(out.keys())\n# hidden_states is all the hidden_states #List[(N,T,D)]\n# last_hidden_state is the last one\n# pooler_output is output of tanh(Linear(last_hidden_state))\n# torch.equal(out['hidden_states'][-1], out['last_hidden_state']) -> True\n# Note that ``out['last_hidden_state'][:,0,:]`` is the CLS token and used for sentence level prediction","metadata":{"id":"OSqc-thubpvM","outputId":"244e8a30-8d6f-48dd-8093-1e90338fdd26","execution":{"iopub.status.busy":"2022-07-06T04:26:55.672343Z","iopub.execute_input":"2022-07-06T04:26:55.672937Z","iopub.status.idle":"2022-07-06T04:26:55.874074Z","shell.execute_reply.started":"2022-07-06T04:26:55.672901Z","shell.execute_reply":"2022-07-06T04:26:55.872987Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states'])\n","output_type":"stream"}]},{"cell_type":"code","source":"out['last_hidden_state'][:,0,:].shape","metadata":{"id":"mQyOEcQRgH5i","outputId":"d883decb-71d7-4149-f1f2-f991576888d5","execution":{"iopub.status.busy":"2022-07-06T04:26:55.878255Z","iopub.execute_input":"2022-07-06T04:26:55.878522Z","iopub.status.idle":"2022-07-06T04:26:55.887827Z","shell.execute_reply.started":"2022-07-06T04:26:55.878497Z","shell.execute_reply":"2022-07-06T04:26:55.886588Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 768])"},"metadata":{}}]},{"cell_type":"code","source":"out = pretrain_model(inputs, attention_mask=attn_masks)\ntorch.equal(out['hidden_states'][-1], out['last_hidden_state'])","metadata":{"id":"NOZSQl70d7Xm","outputId":"0f8999ad-406d-4c89-e607-c95ac15ea585","execution":{"iopub.status.busy":"2022-07-06T04:26:55.889727Z","iopub.execute_input":"2022-07-06T04:26:55.890632Z","iopub.status.idle":"2022-07-06T04:26:56.013493Z","shell.execute_reply.started":"2022-07-06T04:26:55.890558Z","shell.execute_reply":"2022-07-06T04:26:56.012541Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Wrap tokenizer and BERT in Btorch","metadata":{"id":"6C-tgUzGdY8d"}},{"cell_type":"markdown","source":"Here we will freeze the pretrained BERT.  \nUse the `last_hidden_state[:,0,:]` and `last_hidden_state[:,1:,:]` to perform multiHeadAttn.  \nPass the Attn_output to Linear layers and do classification.  \nUse the attn_weight to find out which token has contribute to the classification task.\n\n","metadata":{"id":"tHSzD56ABXlm"}},{"cell_type":"code","source":"class Bert(nn.Module):\n    def __init__(self, pretrain_model, tokenizer, classes, hidden_dim, freeze_pretrain=True):\n        super(Bert, self).__init__()\n        self.pretrain_model = pretrain_model\n        self.tokenizer = tokenizer\n        self.embed_size = pretrain_model.embeddings.word_embeddings.embedding_dim\n        self.classes = classes\n        self.hidden_dim = hidden_dim\n        self.l1 = nn.Linear(self.embed_size, hidden_dim)\n        self.l2 = nn.Linear(hidden_dim, classes)\n        self.last_attn = nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n        if freeze_pretrain:\n          btorch.utils.trainer.freeze(self.pretrain_model)\n    def forward(self, x):\n        x = self.tokenizer(x, padding=True, truncation=True, max_length=50)\n        inputs = torch.tensor(x['input_ids'], device=self.device())\n        attn_masks = torch.tensor(x['attention_mask'], device=self.device())\n        pred = self.pretrain_model(inputs, attention_mask=attn_masks)\n        last_hidden_CLS = pred['last_hidden_state'][:,0,:].unsqueeze(1) #(N,1,E)\n\n        last_hidden_rest = pred['last_hidden_state'][:, 1:, :] # (N,T-1,E)\n        # For a binary mask, a True value indicates that the corresponding key value will be ignored for the purpose of attention.\n        # Here, we want to mask all padding\n        atten_mask_pad = (inputs == 0)[:,1:] #(N,T-1)\n        last_attn_out, last_attn_w = self.last_attn(last_hidden_CLS, last_hidden_rest, last_hidden_rest,\n                                                    key_padding_mask=atten_mask_pad) #(N,1,E), (N,1,T-1)\n        last_attn_out = last_attn_out.squeeze(1)\n        out = torch.relu(self.l1(last_attn_out))\n        out = self.l2(out)\n\n        return out, last_attn_w\n    \n    @classmethod\n    def train_epoch(cls, net, criterion, trainloader, optimizer, epoch_idx, device='cuda', config=None, **kwargs):\n        \"\"\"This is the very basic training function for one epoch. Override this function when necessary\n            \n        Returns:\n            (float or dict): train_loss\n        \"\"\"\n        net.train()\n        train_loss = 0\n        pbar = tqdm(enumerate(trainloader), total=len(trainloader), disable=(kwargs.get(\"verbose\", 1) == 0))\n        batch_idx = 1\n        for batch_idx, (inputs) in pbar:\n            text = inputs['text']\n            targets = inputs['label'].to(net.device())\n            optimizer.zero_grad()\n            predicted = net(text)[0]\n            loss = criterion(predicted, targets)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n\n            pbar.set_description(\n                f\"epoch {epoch_idx + 1} iter {batch_idx}: train loss {loss.item():.5f}.\")\n        return train_loss / (batch_idx + 1)\n\n    @classmethod\n    def test_epoch(cls, net, criterion, testloader, scoring=None, epoch_idx=0, device='cuda', config=None, **kwargs):\n        \"\"\"This is the very basic evaluating function for one epoch. Override this function when necessary\n\n        Args:\n            scoring (Callable, optional): A scoring function that take in ``y_true`` and ``model_output``.\n              Usually, this is your evaluation metric, like accuracy.\n              If provided, this method return a dict that include both loss and score.\n              This scoring function should return the **sum** (set ``reduction=sum``) of the score of a batch.\n              The function signature must be ``scoring(y_true=, model_output=)``.\n              \n        Returns:\n            (float or dict): eval_loss\n        \"\"\"\n        net.eval()\n        test_loss = 0\n        test_score = 0\n        total = 0\n        with torch.inference_mode():\n            for batch_idx, (inputs) in enumerate(testloader):\n                text = inputs['text']\n                targets = inputs['label'].to(net.device())\n                predicted = net(text)[0]\n                loss = criterion(predicted, targets)\n                test_loss += loss.item()\n                if scoring is not None:\n                    score = scoring(model_output=predicted, y_true=targets)\n                    test_score += score\n                total += len(text)\n        if scoring is None:\n            return test_loss / (batch_idx + 1)\n        return {'loss': test_loss / (batch_idx + 1), 'score': test_score / total}\n\n    @classmethod\n    def predict_(cls, net, loader, device='cuda', config=None):\n        \"\"\"This is the very basic predicting function. Override this function when necessary\n            \n        Returns:\n            (list or dict): predict results\n        \"\"\"\n        net.to(device)\n        net.eval()\n        out = {}\n        with torch.inference_mode():\n            for batch_idx, (inputs) in enumerate(loader):\n                text = inputs['text']\n                predicted = net(text)[0]\n                preds_raw = predicted.max(1)[1]\n                for i in range(len(preds_raw)):\n                    out[text[i]] = idx2label[preds_raw[i]]\n        return out","metadata":{"id":"hz1iSFlLdSQL","execution":{"iopub.status.busy":"2022-07-06T05:10:33.704506Z","iopub.execute_input":"2022-07-06T05:10:33.705015Z","iopub.status.idle":"2022-07-06T05:10:33.728663Z","shell.execute_reply.started":"2022-07-06T05:10:33.704978Z","shell.execute_reply":"2022-07-06T05:10:33.727673Z"},"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"def accuarcy(model_output, y_true, reduction='sum'):\n    y_pred = model_output.max(1)[1]\n    out = (y_pred == y_true).float().sum().item()\n    return out\n  \ndef predict_directly(net, x):\n    out = net(x)\n    preds_raw = out[0].max(1)[1]\n    preds = {}\n    for i in range(len(preds_raw)):\n        preds[x[i]] = idx2label[preds_raw[i]]\n    return preds","metadata":{"id":"opude3_1nTdc","execution":{"iopub.status.busy":"2022-07-06T05:10:34.211498Z","iopub.execute_input":"2022-07-06T05:10:34.212183Z","iopub.status.idle":"2022-07-06T05:10:34.219199Z","shell.execute_reply.started":"2022-07-06T05:10:34.212137Z","shell.execute_reply":"2022-07-06T05:10:34.218041Z"},"trusted":true},"execution_count":160,"outputs":[]},{"cell_type":"markdown","source":"## Init Model","metadata":{"id":"dPuZrz3JhtLD"}},{"cell_type":"code","source":"# Model\nmodel = Bert(pretrain_model, tokenizer, 6, 512, freeze_pretrain=True)\n\n# Loss & Optimizer & Config\nmodel._config['max_epoch'] = 50\nmodel._lossfn = nn.CrossEntropyLoss()\nmodel._optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-3)\nmodel._lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model._optimizer, model._config['max_epoch'])\n\n\n# Set GPU\ndevice = model.auto_gpu()","metadata":{"id":"afzvFoJpgfEh","outputId":"aa544728-755d-460b-f15a-5620d38b399d","execution":{"iopub.status.busy":"2022-07-06T05:11:35.882745Z","iopub.execute_input":"2022-07-06T05:11:35.883099Z","iopub.status.idle":"2022-07-06T05:11:35.928757Z","shell.execute_reply.started":"2022-07-06T05:11:35.883070Z","shell.execute_reply":"2022-07-06T05:11:35.927531Z"},"trusted":true},"execution_count":165,"outputs":[{"name":"stdout","text":"auto_gpu: using GPU (Tesla P100-PCIE-16GB)\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.overfit_small_batch(dataset['train'])","metadata":{"execution":{"iopub.status.busy":"2022-07-06T05:11:36.484968Z","iopub.execute_input":"2022-07-06T05:11:36.485330Z","iopub.status.idle":"2022-07-06T05:11:36.489886Z","shell.execute_reply.started":"2022-07-06T05:11:36.485299Z","shell.execute_reply":"2022-07-06T05:11:36.488486Z"},"trusted":true},"execution_count":166,"outputs":[]},{"cell_type":"code","source":"# FIT\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nmodel.fit(dataset['train'], validation_data=dataset['validation'], batch_size=256, workers=4, scoring=accuarcy)","metadata":{"id":"8V8ED9D6hsT7","outputId":"aa3cef33-b100-4cb4-8c0f-65402d55d584","execution":{"iopub.status.busy":"2022-07-06T05:11:37.128008Z","iopub.execute_input":"2022-07-06T05:11:37.128912Z","iopub.status.idle":"2022-07-06T05:35:30.496585Z","shell.execute_reply.started":"2022-07-06T05:11:37.128873Z","shell.execute_reply":"2022-07-06T05:35:30.495313Z"},"trusted":true},"execution_count":167,"outputs":[{"name":"stderr","text":"epoch 1 iter 62: train loss 1.08494.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: Training loss: 2.0569900917628456. Testing loss: {'loss': 1.0325260578393936, 'score': 0.64}\n","output_type":"stream"},{"name":"stderr","text":"epoch 2 iter 62: train loss 0.74592.: 100%|██████████| 63/63 [00:24<00:00,  2.61it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Training loss: 0.9623633377135746. Testing loss: {'loss': 0.7779072192907334, 'score': 0.7315}\n","output_type":"stream"},{"name":"stderr","text":"epoch 3 iter 62: train loss 0.71218.: 100%|██████████| 63/63 [00:24<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Training loss: 0.7620888314549885. Testing loss: {'loss': 0.5789363750070333, 'score': 0.8}\n","output_type":"stream"},{"name":"stderr","text":"epoch 4 iter 62: train loss 0.62098.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Training loss: 0.6865092336185394. Testing loss: {'loss': 0.5582062533944845, 'score': 0.8065}\n","output_type":"stream"},{"name":"stderr","text":"epoch 5 iter 62: train loss 0.83022.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Training loss: 0.6343393964426858. Testing loss: {'loss': 0.5231420259773731, 'score': 0.827}\n","output_type":"stream"},{"name":"stderr","text":"epoch 6 iter 62: train loss 0.80069.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Training loss: 0.6339042281347608. Testing loss: {'loss': 0.6424216949939727, 'score': 0.7785}\n","output_type":"stream"},{"name":"stderr","text":"epoch 7 iter 62: train loss 0.68073.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Training loss: 0.6413942074018811. Testing loss: {'loss': 0.480013039663434, 'score': 0.8205}\n","output_type":"stream"},{"name":"stderr","text":"epoch 8 iter 62: train loss 0.55086.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Training loss: 0.6275160728938995. Testing loss: {'loss': 0.516177862405777, 'score': 0.819}\n","output_type":"stream"},{"name":"stderr","text":"epoch 9 iter 62: train loss 0.73070.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Training loss: 0.6080800990263621. Testing loss: {'loss': 0.48831953866779804, 'score': 0.8295}\n","output_type":"stream"},{"name":"stderr","text":"epoch 10 iter 62: train loss 0.64955.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Training loss: 0.6073610437294793. Testing loss: {'loss': 0.5090148499011994, 'score': 0.8335}\n","output_type":"stream"},{"name":"stderr","text":"epoch 11 iter 62: train loss 0.50002.: 100%|██████████| 63/63 [00:24<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Training loss: 0.6085292720605456. Testing loss: {'loss': 0.5202297216877342, 'score': 0.8215}\n","output_type":"stream"},{"name":"stderr","text":"epoch 12 iter 62: train loss 0.53114.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Training loss: 0.5868179845431495. Testing loss: {'loss': 0.47013306224346163, 'score': 0.8345}\n","output_type":"stream"},{"name":"stderr","text":"epoch 13 iter 62: train loss 0.55237.: 100%|██████████| 63/63 [00:24<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Training loss: 0.5782815738329812. Testing loss: {'loss': 0.4999255694448948, 'score': 0.827}\n","output_type":"stream"},{"name":"stderr","text":"epoch 14 iter 62: train loss 0.65309.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Training loss: 0.6110917173680805. Testing loss: {'loss': 0.5010169743001461, 'score': 0.83}\n","output_type":"stream"},{"name":"stderr","text":"epoch 15 iter 62: train loss 0.55696.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Training loss: 0.5857805297488258. Testing loss: {'loss': 0.4452160780504346, 'score': 0.833}\n","output_type":"stream"},{"name":"stderr","text":"epoch 16 iter 62: train loss 0.55538.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Training loss: 0.5489872154735383. Testing loss: {'loss': 0.44282731814682486, 'score': 0.842}\n","output_type":"stream"},{"name":"stderr","text":"epoch 17 iter 62: train loss 0.50922.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Training loss: 0.5453284803837065. Testing loss: {'loss': 0.4171503846645355, 'score': 0.8445}\n","output_type":"stream"},{"name":"stderr","text":"epoch 18 iter 62: train loss 0.44128.: 100%|██████████| 63/63 [00:24<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Training loss: 0.5324177056077927. Testing loss: {'loss': 0.4893925714790821, 'score': 0.8325}\n","output_type":"stream"},{"name":"stderr","text":"epoch 19 iter 62: train loss 0.52886.: 100%|██████████| 63/63 [00:24<00:00,  2.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Training loss: 0.531824114776793. Testing loss: {'loss': 0.4499558520168066, 'score': 0.8325}\n","output_type":"stream"},{"name":"stderr","text":"epoch 20 iter 62: train loss 0.54330.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Training loss: 0.5284544385614849. Testing loss: {'loss': 0.4385626876950264, 'score': 0.848}\n","output_type":"stream"},{"name":"stderr","text":"epoch 21 iter 62: train loss 0.70328.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Training loss: 0.5152408816511669. Testing loss: {'loss': 0.40073660691827534, 'score': 0.8635}\n","output_type":"stream"},{"name":"stderr","text":"epoch 22 iter 62: train loss 0.43363.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Training loss: 0.5042646688128275. Testing loss: {'loss': 0.41557471922785044, 'score': 0.8505}\n","output_type":"stream"},{"name":"stderr","text":"epoch 23 iter 62: train loss 0.51574.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Training loss: 0.5034566682482523. Testing loss: {'loss': 0.40832123352587224, 'score': 0.849}\n","output_type":"stream"},{"name":"stderr","text":"epoch 24 iter 62: train loss 0.42868.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Training loss: 0.5000937689864446. Testing loss: {'loss': 0.3787285519912839, 'score': 0.8655}\n","output_type":"stream"},{"name":"stderr","text":"epoch 25 iter 62: train loss 0.42891.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Training loss: 0.48062051383275833. Testing loss: {'loss': 0.3639151740819216, 'score': 0.8665}\n","output_type":"stream"},{"name":"stderr","text":"epoch 26 iter 62: train loss 0.44759.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Training loss: 0.4788284448404161. Testing loss: {'loss': 0.39925728768855334, 'score': 0.857}\n","output_type":"stream"},{"name":"stderr","text":"epoch 27 iter 62: train loss 0.44301.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Training loss: 0.4806964449466221. Testing loss: {'loss': 0.37370242217928173, 'score': 0.8605}\n","output_type":"stream"},{"name":"stderr","text":"epoch 28 iter 62: train loss 0.49104.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Training loss: 0.46383692300508894. Testing loss: {'loss': 0.36458585078269246, 'score': 0.8675}\n","output_type":"stream"},{"name":"stderr","text":"epoch 29 iter 62: train loss 0.39854.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Training loss: 0.4614448523710644. Testing loss: {'loss': 0.3847260010614991, 'score': 0.8545}\n","output_type":"stream"},{"name":"stderr","text":"epoch 30 iter 62: train loss 0.39200.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Training loss: 0.4523891361932906. Testing loss: {'loss': 0.36460928690433503, 'score': 0.865}\n","output_type":"stream"},{"name":"stderr","text":"epoch 31 iter 62: train loss 0.51373.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 30: Training loss: 0.4338012120080373. Testing loss: {'loss': 0.3535870287530124, 'score': 0.873}\n","output_type":"stream"},{"name":"stderr","text":"epoch 32 iter 62: train loss 0.37449.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 31: Training loss: 0.4288468100721874. Testing loss: {'loss': 0.3721816559880972, 'score': 0.8665}\n","output_type":"stream"},{"name":"stderr","text":"epoch 33 iter 62: train loss 0.37244.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 32: Training loss: 0.44002383001266965. Testing loss: {'loss': 0.3443417135551572, 'score': 0.8735}\n","output_type":"stream"},{"name":"stderr","text":"epoch 34 iter 62: train loss 0.58814.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 33: Training loss: 0.4233548187074207. Testing loss: {'loss': 0.33603232650458814, 'score': 0.878}\n","output_type":"stream"},{"name":"stderr","text":"epoch 35 iter 62: train loss 0.48231.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 34: Training loss: 0.4192131147498176. Testing loss: {'loss': 0.33284290612861517, 'score': 0.8775}\n","output_type":"stream"},{"name":"stderr","text":"epoch 36 iter 62: train loss 0.50638.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 35: Training loss: 0.4199819176916092. Testing loss: {'loss': 0.3360182695686817, 'score': 0.881}\n","output_type":"stream"},{"name":"stderr","text":"epoch 37 iter 62: train loss 0.36824.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 36: Training loss: 0.4067628246451181. Testing loss: {'loss': 0.3337050585746765, 'score': 0.8805}\n","output_type":"stream"},{"name":"stderr","text":"epoch 38 iter 62: train loss 0.43327.: 100%|██████████| 63/63 [00:24<00:00,  2.55it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 37: Training loss: 0.4104379713535309. Testing loss: {'loss': 0.3359418839178979, 'score': 0.8775}\n","output_type":"stream"},{"name":"stderr","text":"epoch 39 iter 62: train loss 0.45569.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 38: Training loss: 0.39657534871782574. Testing loss: {'loss': 0.3327499318830669, 'score': 0.8795}\n","output_type":"stream"},{"name":"stderr","text":"epoch 40 iter 62: train loss 0.46396.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 39: Training loss: 0.3897934253253634. Testing loss: {'loss': 0.3269292581267655, 'score': 0.8805}\n","output_type":"stream"},{"name":"stderr","text":"epoch 41 iter 62: train loss 0.34529.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 40: Training loss: 0.3916659099715097. Testing loss: {'loss': 0.3280732242334634, 'score': 0.8775}\n","output_type":"stream"},{"name":"stderr","text":"epoch 42 iter 62: train loss 0.28414.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 41: Training loss: 0.3862795508097088. Testing loss: {'loss': 0.32136385383084415, 'score': 0.878}\n","output_type":"stream"},{"name":"stderr","text":"epoch 43 iter 62: train loss 0.35586.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 42: Training loss: 0.3780378500620524. Testing loss: {'loss': 0.3203253073990345, 'score': 0.8835}\n","output_type":"stream"},{"name":"stderr","text":"epoch 44 iter 62: train loss 0.49145.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 43: Training loss: 0.3752086777535696. Testing loss: {'loss': 0.3211224777549505, 'score': 0.8855}\n","output_type":"stream"},{"name":"stderr","text":"epoch 45 iter 62: train loss 0.31170.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 44: Training loss: 0.3722893808569227. Testing loss: {'loss': 0.32892869898304344, 'score': 0.8815}\n","output_type":"stream"},{"name":"stderr","text":"epoch 46 iter 62: train loss 0.38885.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 45: Training loss: 0.3725225920715029. Testing loss: {'loss': 0.32470373610034586, 'score': 0.8815}\n","output_type":"stream"},{"name":"stderr","text":"epoch 47 iter 62: train loss 0.43722.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 46: Training loss: 0.36976195517040433. Testing loss: {'loss': 0.32001885280013087, 'score': 0.881}\n","output_type":"stream"},{"name":"stderr","text":"epoch 48 iter 62: train loss 0.36591.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 47: Training loss: 0.3705322226834676. Testing loss: {'loss': 0.31797681203857064, 'score': 0.8845}\n","output_type":"stream"},{"name":"stderr","text":"epoch 49 iter 62: train loss 0.30910.: 100%|██████████| 63/63 [00:24<00:00,  2.59it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 48: Training loss: 0.3714562101023538. Testing loss: {'loss': 0.31834576167166234, 'score': 0.882}\n","output_type":"stream"},{"name":"stderr","text":"epoch 50 iter 62: train loss 0.36368.: 100%|██████████| 63/63 [00:24<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 49: Training loss: 0.3632987860649351. Testing loss: {'loss': 0.31805257563106715, 'score': 0.8825}\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(dataset['test'], scoring=accuarcy)","metadata":{"id":"XLbquf5t4ORo","outputId":"20c89777-a111-4b66-8569-807608610263","execution":{"iopub.status.busy":"2022-07-06T05:35:30.498953Z","iopub.execute_input":"2022-07-06T05:35:30.499354Z","iopub.status.idle":"2022-07-06T05:35:34.539205Z","shell.execute_reply.started":"2022-07-06T05:35:30.499312Z","shell.execute_reply":"2022-07-06T05:35:34.538184Z"},"trusted":true},"execution_count":168,"outputs":[{"execution_count":168,"output_type":"execute_result","data":{"text/plain":"{'loss': 0.35295420640334485, 'score': 0.8695}"},"metadata":{}}]},{"cell_type":"code","source":"idx2label = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\nx = ['I am sad', 'I am happy', 'i stopped feeling cold and began feeling hot', \n     'what the heck is this', \"i don't care what you do\", 'I love you 3000', 'I love you in every universe']\ny = [0, 1, 3, 4, 3, 2, 2]\npreds = predict_directly(model, x)\npreds","metadata":{"id":"ztw_tPoUjYR-","outputId":"1793f453-416e-4f5d-d98d-a6583ba894ac","execution":{"iopub.status.busy":"2022-07-06T05:35:34.540850Z","iopub.execute_input":"2022-07-06T05:35:34.541533Z","iopub.status.idle":"2022-07-06T05:35:34.564471Z","shell.execute_reply.started":"2022-07-06T05:35:34.541490Z","shell.execute_reply":"2022-07-06T05:35:34.563570Z"},"trusted":true},"execution_count":169,"outputs":[{"execution_count":169,"output_type":"execute_result","data":{"text/plain":"{'I am sad': 'sadness',\n 'I am happy': 'joy',\n 'i stopped feeling cold and began feeling hot': 'anger',\n 'what the heck is this': 'anger',\n \"i don't care what you do\": 'anger',\n 'I love you 3000': 'anger',\n 'I love you in every universe': 'joy'}"},"metadata":{}}]},{"cell_type":"code","source":"display(x)\nx_token = tokenizer(x, padding=True, truncation=True, max_length=50)['input_ids']\ndisplay(x_token)\n[tokenizer.decode(i, padding=True, truncation=True, max_length=50) for i in x_token]","metadata":{"execution":{"iopub.status.busy":"2022-07-06T05:35:34.567136Z","iopub.execute_input":"2022-07-06T05:35:34.567493Z","iopub.status.idle":"2022-07-06T05:35:34.584336Z","shell.execute_reply.started":"2022-07-06T05:35:34.567458Z","shell.execute_reply":"2022-07-06T05:35:34.583322Z"},"trusted":true},"execution_count":170,"outputs":[{"output_type":"display_data","data":{"text/plain":"['I am sad',\n 'I am happy',\n 'i stopped feeling cold and began feeling hot',\n 'what the heck is this',\n \"i don't care what you do\",\n 'I love you 3000',\n 'I love you in every universe']"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"[[101, 1045, 2572, 6517, 102, 0, 0, 0, 0, 0],\n [101, 1045, 2572, 3407, 102, 0, 0, 0, 0, 0],\n [101, 1045, 3030, 3110, 3147, 1998, 2211, 3110, 2980, 102],\n [101, 2054, 1996, 17752, 2003, 2023, 102, 0, 0, 0],\n [101, 1045, 2123, 1005, 1056, 2729, 2054, 2017, 2079, 102],\n [101, 1045, 2293, 2017, 11910, 102, 0, 0, 0, 0],\n [101, 1045, 2293, 2017, 1999, 2296, 5304, 102, 0, 0]]"},"metadata":{}},{"execution_count":170,"output_type":"execute_result","data":{"text/plain":"['[CLS] i am sad [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] i am happy [SEP] [PAD] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] i stopped feeling cold and began feeling hot [SEP]',\n '[CLS] what the heck is this [SEP] [PAD] [PAD] [PAD]',\n \"[CLS] i don't care what you do [SEP]\",\n '[CLS] i love you 3000 [SEP] [PAD] [PAD] [PAD] [PAD]',\n '[CLS] i love you in every universe [SEP] [PAD] [PAD]']"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we try to visualize which word contribute to the prediction.  \nThe higher attn weight tell us which token is important.  ","metadata":{"id":"dmcbWG8EMtEf"}},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n\npred, w = model(x)\nfor idx in range(0, len(x)):\n    print(y[idx], idx)\n    print(f\"Prediction: {idx2label[pred[idx].argmax().item()]}. Ground-Truth: {idx2label[y[idx]]}\")\n    print(f\"Prediction: {pred[idx].argmax().item()}. Ground-Truth: {y[idx]}\")\n    print(x[idx])\n    print(w[idx])\n    w_pure = w[idx][w[idx] !=0 ].cpu().detach().numpy()\n    # Here tokenizer.tokenize will not help use add ['CLS']['SEP'], so we manually add it.\n    # Remeber the weight doesn't contains ['CLS'], so we only add ['SEP'].\n    tokens_pure = tokenizer.tokenize(x[idx])+['<SEP>']\n    tokens = [f\"{i}_{tokens_pure[i]}\" for i in range(len(tokens_pure))]\n    full = list(zip(tokens, w_pure))\n    display(full)\n\n    out = []\n    out.append(list(full[0]))\n    for i in range(1, len(full)):\n        if full[i][0][:2] == '##':\n            out[-1][0] += full[i][0][2:]\n            out[-1][1] += full[i][1]\n        else:\n            out.append(list(full[i]))\n    sorted(out, key=lambda out: out[1], reverse=True)\n\n    \n    df = pd.DataFrame(w_pure, index=tokens_pure, columns=['attn_weight'])\n    plt.figure(figsize=(10,1.3))\n    fig = sns.heatmap(df.T, fmt=\"g\", cmap='viridis',xticklabels=tokens_pure)\n    fig.get_figure().savefig(\"out.png\",bbox_inches='tight', dpi=300) \n","metadata":{"id":"nVtEgNmk8_5h","outputId":"7c9cb7dd-ad77-4b8f-c58c-9022c6af7369","execution":{"iopub.status.busy":"2022-07-06T05:35:34.586549Z","iopub.execute_input":"2022-07-06T05:35:34.587472Z","iopub.status.idle":"2022-07-06T05:35:37.815555Z","shell.execute_reply.started":"2022-07-06T05:35:34.587434Z","shell.execute_reply":"2022-07-06T05:35:37.814600Z"},"trusted":true},"execution_count":171,"outputs":[{"name":"stdout","text":"0 0\nPrediction: sadness. Ground-Truth: sadness\nPrediction: 0. Ground-Truth: 0\nI am sad\ntensor([[0.1578, 0.1710, 0.5365, 0.1347, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.15775517),\n ('1_am', 0.17102455),\n ('2_sad', 0.5364807),\n ('3_<SEP>', 0.13473956)]"},"metadata":{}},{"name":"stdout","text":"1 1\nPrediction: joy. Ground-Truth: joy\nPrediction: 1. Ground-Truth: 1\nI am happy\ntensor([[0.1410, 0.1838, 0.5409, 0.1343, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.1410408),\n ('1_am', 0.18379824),\n ('2_happy', 0.54090506),\n ('3_<SEP>', 0.13425589)]"},"metadata":{}},{"name":"stdout","text":"3 2\nPrediction: anger. Ground-Truth: anger\nPrediction: 3. Ground-Truth: 3\ni stopped feeling cold and began feeling hot\ntensor([[0.1065, 0.0539, 0.0984, 0.3021, 0.0547, 0.0458, 0.0662, 0.2271, 0.0453]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.10651444),\n ('1_stopped', 0.053923905),\n ('2_feeling', 0.098370075),\n ('3_cold', 0.30211294),\n ('4_and', 0.05466548),\n ('5_began', 0.045782972),\n ('6_feeling', 0.06616807),\n ('7_hot', 0.227149),\n ('8_<SEP>', 0.045313127)]"},"metadata":{}},{"name":"stdout","text":"4 3\nPrediction: anger. Ground-Truth: fear\nPrediction: 3. Ground-Truth: 4\nwhat the heck is this\ntensor([[0.1934, 0.1510, 0.0834, 0.0933, 0.1443, 0.3346, 0.0000, 0.0000, 0.0000]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_what', 0.1933646),\n ('1_the', 0.15098034),\n ('2_heck', 0.0834205),\n ('3_is', 0.09330206),\n ('4_this', 0.14433116),\n ('5_<SEP>', 0.33460134)]"},"metadata":{}},{"name":"stdout","text":"3 4\nPrediction: anger. Ground-Truth: anger\nPrediction: 3. Ground-Truth: 3\ni don't care what you do\ntensor([[0.1084, 0.1278, 0.0810, 0.2095, 0.0771, 0.0779, 0.1910, 0.0801, 0.0471]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.10840963),\n ('1_don', 0.127796),\n (\"2_'\", 0.08104326),\n ('3_t', 0.20953275),\n ('4_care', 0.07714799),\n ('5_what', 0.0778849),\n ('6_you', 0.19104694),\n ('7_do', 0.08006022),\n ('8_<SEP>', 0.047078326)]"},"metadata":{}},{"name":"stdout","text":"2 5\nPrediction: anger. Ground-Truth: love\nPrediction: 3. Ground-Truth: 2\nI love you 3000\ntensor([[0.1016, 0.1810, 0.1585, 0.4649, 0.0939, 0.0000, 0.0000, 0.0000, 0.0000]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.101639844),\n ('1_love', 0.18103257),\n ('2_you', 0.1585277),\n ('3_3000', 0.46486628),\n ('4_<SEP>', 0.09393363)]"},"metadata":{}},{"name":"stdout","text":"2 6\nPrediction: joy. Ground-Truth: love\nPrediction: 1. Ground-Truth: 2\nI love you in every universe\ntensor([[0.1173, 0.2317, 0.1491, 0.0643, 0.0644, 0.1161, 0.2571, 0.0000, 0.0000]],\n       device='cuda:0', grad_fn=<SelectBackward0>)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.117307425),\n ('1_love', 0.23168395),\n ('2_you', 0.14913762),\n ('3_in', 0.064302325),\n ('4_every', 0.06441341),\n ('5_universe', 0.116087526),\n ('6_<SEP>', 0.25706774)]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]}]}