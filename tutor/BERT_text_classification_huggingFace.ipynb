{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install git+https://github.com/brianbt/btorch\n!pip install transformers\n!pip install pip install datasets","metadata":{"id":"KuHpQ3H4UmcP","outputId":"e24d50bc-c7e7-452b-9e3b-bba7fe025a89","execution":{"iopub.status.busy":"2022-07-04T12:59:27.030405Z","iopub.execute_input":"2022-07-04T12:59:27.030979Z","iopub.status.idle":"2022-07-04T13:00:01.204626Z","shell.execute_reply.started":"2022-07-04T12:59:27.030936Z","shell.execute_reply":"2022-07-04T13:00:01.203473Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Collecting git+https://github.com/brianbt/btorch\n  Cloning https://github.com/brianbt/btorch to /tmp/pip-req-build-hw8jfwzv\n  Running command git clone --filter=blob:none --quiet https://github.com/brianbt/btorch /tmp/pip-req-build-hw8jfwzv\n  Resolved https://github.com/brianbt/btorch to commit 10a0e2f09ac4e9dd937843846aa20e3d7d383f95\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hRequirement already satisfied: torch in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.11.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (0.12.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.21.6)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.3.5)\nCollecting torchinfo\n  Downloading torchinfo-1.7.0-py3-none-any.whl (22 kB)\nRequirement already satisfied: opencv-python in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (4.5.4.60)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.0.2)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (3.5.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (4.64.0)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from btorch==0.0.1) (1.7.3)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (0.11.0)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (9.1.1)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (3.0.9)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (1.4.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (4.33.3)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (21.3)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib->btorch==0.0.1) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->btorch==0.0.1) (2022.1)\nRequirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->btorch==0.0.1) (1.1.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->btorch==0.0.1) (3.1.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch->btorch==0.0.1) (4.1.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torchvision->btorch==0.0.1) (2.27.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib->btorch==0.0.1) (1.16.0)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (3.3)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (2022.6.15)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->torchvision->btorch==0.0.1) (2.0.12)\nBuilding wheels for collected packages: btorch\n  Building wheel for btorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for btorch: filename=btorch-0.0.1-py3-none-any.whl size=53028 sha256=b26321f9e4754c63ca48165d965b05ab92e8696e2d248f3c8bd382567ba7086b\n  Stored in directory: /tmp/pip-ephem-wheel-cache-xz5au4w1/wheels/fa/ef/1e/1248ce8683f1b6fd8e6552260da8c1dcfbb352d899fef03d72\nSuccessfully built btorch\nInstalling collected packages: torchinfo, btorch\nSuccessfully installed btorch-0.0.1 torchinfo-1.7.0\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: transformers in /opt/conda/lib/python3.7/site-packages (4.18.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (2021.11.10)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from transformers) (4.11.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from transformers) (1.21.6)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.6.0)\nRequirement already satisfied: sacremoses in /opt/conda/lib/python3.7/site-packages (from transformers) (0.0.53)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (6.0)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (21.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.27.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.64.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.7.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/conda/lib/python3.7/site-packages (from transformers) (0.12.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.8.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2022.6.15)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.26.9)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.3)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.0.12)\nRequirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.16.0)\nRequirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.4)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0mRequirement already satisfied: pip in /opt/conda/lib/python3.7/site-packages (22.1.1)\nCollecting install\n  Downloading install-1.3.5-py3-none-any.whl (3.2 kB)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.7/site-packages (2.1.0)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.7.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.7/site-packages (from datasets) (3.8.1)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.7/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.7/site-packages (from datasets) (0.70.13)\nRequirement already satisfied: dill in /opt/conda/lib/python3.7/site-packages (from datasets) (0.3.5.1)\nRequirement already satisfied: importlib-metadata in /opt/conda/lib/python3.7/site-packages (from datasets) (4.11.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (5.0.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.7/site-packages (from datasets) (1.21.6)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.7/site-packages (from datasets) (4.64.0)\nRequirement already satisfied: fsspec[http]>=2021.05.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2022.5.0)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.7/site-packages (from datasets) (3.0.0)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.7/site-packages (from datasets) (1.3.5)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.7/site-packages (from datasets) (2.27.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.6.0)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.7/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->datasets) (3.0.9)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (1.26.9)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2022.6.15)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (2.0.12)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests>=2.19.0->datasets) (3.3)\nRequirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (4.0.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.2.0)\nRequirement already satisfied: asynctest==0.13.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (0.13.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (1.7.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (21.4.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.7/site-packages (from aiohttp->datasets) (6.0.2)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata->datasets) (3.8.0)\nRequirement already satisfied: python-dateutil>=2.7.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2.8.2)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.7/site-packages (from pandas->datasets) (2022.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.16.0)\nInstalling collected packages: install\nSuccessfully installed install-1.3.5\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"markdown","source":"# Import","metadata":{"id":"R-b4AZoFZcX4"}},{"cell_type":"code","source":"import torch\nfrom tqdm import tqdm\n\n# Btorch\nimport btorch\nfrom btorch import nn\nimport btorch.nn.functional as F\n\n# Hugging Face\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoConfig, AutoModel","metadata":{"id":"BRBNaal2UwIC","execution":{"iopub.status.busy":"2022-07-04T13:00:01.207126Z","iopub.execute_input":"2022-07-04T13:00:01.207500Z","iopub.status.idle":"2022-07-04T13:00:07.989846Z","shell.execute_reply.started":"2022-07-04T13:00:01.207462Z","shell.execute_reply":"2022-07-04T13:00:07.988910Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Load dataset","metadata":{"id":"8c8Kv2NIZaA7"}},{"cell_type":"code","source":"# https://huggingface.co/datasets/emotion\n# this dataset have 6 classes\nidx2label = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\n\ndataset = load_dataset(\"emotion\")\nprint(dataset)\n# Lets check how one datapoint looks like\nprint(next(iter(dataset['train'])))","metadata":{"id":"WGfSENxsWtRj","outputId":"77216628-6396-4269-bb72-b193d1367792","execution":{"iopub.status.busy":"2022-07-04T13:00:07.991289Z","iopub.execute_input":"2022-07-04T13:00:07.991911Z","iopub.status.idle":"2022-07-04T13:00:19.565262Z","shell.execute_reply.started":"2022-07-04T13:00:07.991862Z","shell.execute_reply":"2022-07-04T13:00:19.564236Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/1.66k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"364ca507a9f046debf12f436116ce711"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading metadata:   0%|          | 0.00/1.61k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4a733278418f4ebc8cbc16ddceae941f"}},"metadata":{}},{"name":"stdout","text":"Downloading and preparing dataset emotion/default (download: 1.97 MiB, generated: 2.07 MiB, post-processed: Unknown size, total: 4.05 MiB) to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.66M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e10fb271d3194f5a93a63052fcf26319"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/204k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6d03e9c2b89a4ad88515c1397f69f5a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/207k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b55dfd7caa394966abf225eebc32cbd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"name":"stdout","text":"Dataset emotion downloaded and prepared to /root/.cache/huggingface/datasets/emotion/default/0.0.0/348f63ca8e27b3713b6c04d723efe6d824a56fb3d1449794716c0f0296072705. Subsequent calls will reuse this data.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c9b728fb6f854b4cbd488ab5aa43f0f9"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label'],\n        num_rows: 16000\n    })\n    validation: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n    test: Dataset({\n        features: ['text', 'label'],\n        num_rows: 2000\n    })\n})\n{'text': 'i didnt feel humiliated', 'label': 0}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Create HuggingFace BERT 🤗 ","metadata":{"id":"J3XLAdmZZd6U"}},{"cell_type":"code","source":"#https://huggingface.co/bert-base-uncased\nmodel_name = 'bert-base-uncased'\n\n# You can check the config parameter options from the below links\n#https://huggingface.co/docs/transformers/v4.20.1/en/main_classes/configuration#transformers.PretrainedConfig\n#https://huggingface.co/docs/transformers/v4.20.1/en/model_doc/bert#transformers.BertConfig\nconfig = AutoConfig.from_pretrained(\n    model_name, \n    output_hidden_states = True,\n    output_attention = True,\n    hidden_dropout_prob = 0.2,\n) \nprint(config)\n\n# Use above config to create our BERT model\npretrain_model = AutoModel.from_pretrained(\n    model_name,\n    config = config\n)\n\n# Create a BERT tokenizer\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"id":"O5tU8u94VTOe","outputId":"3c319b4f-ec64-4b00-ce3e-6d442c318665","execution":{"iopub.status.busy":"2022-07-04T13:00:19.568088Z","iopub.execute_input":"2022-07-04T13:00:19.568700Z","iopub.status.idle":"2022-07-04T13:00:47.460775Z","shell.execute_reply.started":"2022-07-04T13:00:19.568663Z","shell.execute_reply":"2022-07-04T13:00:47.459821Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92a222e0e181439bb516784e935ee293"}},"metadata":{}},{"name":"stdout","text":"BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.2,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"output_hidden_states\": true,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.18.0\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dfacb749eb7144afa4e298722b0c094e"}},"metadata":{}},{"name":"stderr","text":"Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77ae400a563e4bdb95eff1de8ce93274"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9df330719297485291f1d5e377224e64"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"85fbf95b7bd04f1587ab0ad98c6d3d74"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Quick tutor for tokenizer usgage","metadata":{"id":"T08jXqOjZuVh"}},{"cell_type":"code","source":"x = ['i didnt feel humiliated',\n     'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n     'im grabbing a minute to post i feel greedy wrong']\ny = [0,\n     0,\n     3]","metadata":{"id":"pAfrw0bcZxnW","execution":{"iopub.status.busy":"2022-07-04T13:00:47.462185Z","iopub.execute_input":"2022-07-04T13:00:47.462532Z","iopub.status.idle":"2022-07-04T13:00:47.467050Z","shell.execute_reply.started":"2022-07-04T13:00:47.462496Z","shell.execute_reply":"2022-07-04T13:00:47.466076Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Since each data in one batch must have same size. We do padding and truncation such that the length is 10 for each sentence.\n# The padding idx will be ``0``\ntokens = tokenizer(x, padding=True, truncation=True, max_length=10)\ndisplay(tokens['input_ids'])\n","metadata":{"id":"Gb89owk5Z4f_","outputId":"447a7d2a-25d4-443f-e79f-18bfbaa4837a","execution":{"iopub.status.busy":"2022-07-04T13:00:47.468550Z","iopub.execute_input":"2022-07-04T13:00:47.469111Z","iopub.status.idle":"2022-07-04T13:00:47.494508Z","shell.execute_reply.started":"2022-07-04T13:00:47.469075Z","shell.execute_reply":"2022-07-04T13:00:47.493592Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"[[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0],\n [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 102],\n [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 102]]"},"metadata":{}}]},{"cell_type":"code","source":"# This is either 0 or 1.\n# Remeber training data for BERT have two parts. \n# The first is indicated as 0, the second is indicated as 1\ndisplay(tokens['token_type_ids'])","metadata":{"id":"iimxfodiaV7R","outputId":"c6d218a5-e0fc-4560-a3aa-76d795a61229","execution":{"iopub.status.busy":"2022-07-04T13:00:47.496000Z","iopub.execute_input":"2022-07-04T13:00:47.496606Z","iopub.status.idle":"2022-07-04T13:00:47.503594Z","shell.execute_reply.started":"2022-07-04T13:00:47.496571Z","shell.execute_reply":"2022-07-04T13:00:47.502679Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"[[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]"},"metadata":{}}]},{"cell_type":"code","source":"# This is attention mask.\n# 0 means attention should be see those words\n# Becoz those words is padded\ndisplay(tokens['attention_mask'])","metadata":{"id":"dt4XMSifbOn0","outputId":"016bdb74-d843-4ef2-a4bf-0e86a623dbed","execution":{"iopub.status.busy":"2022-07-04T13:00:47.505124Z","iopub.execute_input":"2022-07-04T13:00:47.505473Z","iopub.status.idle":"2022-07-04T13:00:47.516220Z","shell.execute_reply.started":"2022-07-04T13:00:47.505441Z","shell.execute_reply":"2022-07-04T13:00:47.515119Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"[[1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]"},"metadata":{}}]},{"cell_type":"markdown","source":"## Quick tutor for BERT usgage","metadata":{"id":"MrIsIzIjb-62"}},{"cell_type":"code","source":"# here (N,T) is (3, max_length=10)\ninputs = torch.tensor(tokens['input_ids'])\nattn_masks = torch.tensor(tokens['attention_mask'])\n# Hugging Face BERT will produce three thing for us base on how we set the config\nout = pretrain_model(inputs, attention_mask=attn_masks)\nprint(out.keys())\n# hidden_states is all the hidden_states #List[(N,T,D)]\n# last_hidden_state is the last one\n# pooler_output is output of tanh(Linear(last_hidden_state))\n# torch.equal(out['hidden_states'][-1], out['last_hidden_state']) -> True\n# Note that ``out['last_hidden_state'][:,0,:]`` is the CLS token and used for sentence level prediction","metadata":{"id":"OSqc-thubpvM","outputId":"244e8a30-8d6f-48dd-8093-1e90338fdd26","execution":{"iopub.status.busy":"2022-07-04T13:00:47.517969Z","iopub.execute_input":"2022-07-04T13:00:47.518618Z","iopub.status.idle":"2022-07-04T13:00:47.706434Z","shell.execute_reply.started":"2022-07-04T13:00:47.518585Z","shell.execute_reply":"2022-07-04T13:00:47.705081Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states'])\n","output_type":"stream"}]},{"cell_type":"code","source":"out['last_hidden_state'][:,0,:].shape","metadata":{"id":"mQyOEcQRgH5i","outputId":"d883decb-71d7-4149-f1f2-f991576888d5","execution":{"iopub.status.busy":"2022-07-04T13:00:47.710198Z","iopub.execute_input":"2022-07-04T13:00:47.710493Z","iopub.status.idle":"2022-07-04T13:00:47.719338Z","shell.execute_reply.started":"2022-07-04T13:00:47.710465Z","shell.execute_reply":"2022-07-04T13:00:47.718205Z"},"trusted":true},"execution_count":19,"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"torch.Size([3, 768])"},"metadata":{}}]},{"cell_type":"code","source":"out = pretrain_model(inputs, attention_mask=attn_masks)\ntorch.equal(out['hidden_states'][-1], out['last_hidden_state'])","metadata":{"id":"NOZSQl70d7Xm","outputId":"0f8999ad-406d-4c89-e607-c95ac15ea585","execution":{"iopub.status.busy":"2022-07-04T13:00:47.721079Z","iopub.execute_input":"2022-07-04T13:00:47.721801Z","iopub.status.idle":"2022-07-04T13:00:47.836267Z","shell.execute_reply.started":"2022-07-04T13:00:47.721753Z","shell.execute_reply":"2022-07-04T13:00:47.835165Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"markdown","source":"# Wrap tokenizer and BERT in Btorch","metadata":{"id":"6C-tgUzGdY8d"}},{"cell_type":"markdown","source":"Here we will freeze the pretrained BERT.  \nUse the `last_hidden_state[:,0,:]` and `last_hidden_state[:,1:,:]` to perform multiHeadAttn.  \nPass the Attn_output to Linear layers and do classification.  \nUse the attn_weight to find out which token has contribute to the classification task.\n\n","metadata":{"id":"tHSzD56ABXlm"}},{"cell_type":"code","source":"class Bert(nn.Module):\n    def __init__(self, pretrain_model, tokenizer, classes, hidden_dim, freeze_pretrain=True):\n        super(Bert, self).__init__()\n        self.pretrain_model = pretrain_model\n        self.tokenizer = tokenizer\n        self.embed_size = pretrain_model.embeddings.word_embeddings.embedding_dim\n        self.classes = classes\n        self.hidden_dim = hidden_dim\n        self.l1 = nn.Linear(self.embed_size, hidden_dim)\n        self.l2 = nn.Linear(hidden_dim, classes)\n        self.last_attn = nn.MultiheadAttention(self.embed_size, 8, batch_first=True)\n        if freeze_pretrain:\n          btorch.utils.trainer.freeze(self.pretrain_model)\n    def forward(self, x):\n        x = self.tokenizer(x, padding=True, truncation=True, max_length=50)\n        inputs = torch.tensor(x['input_ids'], device=self.device())\n        attn_masks = torch.tensor(x['attention_mask'], device=self.device())\n        pred = self.pretrain_model(inputs, attention_mask=attn_masks)\n        last_hidden_CLS = pred['last_hidden_state'][:,0,:].unsqueeze(1) #(N,1,E)\n\n        last_hidden_rest = pred['last_hidden_state'][:, 1:, :] # (N,T-1,E)\n        # For a binary mask, a True value indicates that the corresponding key value will be ignored for the purpose of attention.\n        # Here, we want to mask all padding\n        atten_mask_pad = (inputs == 0)[:,1:] #(N,T-1)\n        last_attn_out, last_attn_w = self.last_attn(last_hidden_CLS, last_hidden_rest, last_hidden_rest,\n                                                    key_padding_mask=atten_mask_pad) #(N,1,E), (N,1,T-1)\n        last_attn_out = last_attn_out.squeeze(1)\n        out = torch.relu(self.l1(last_attn_out))\n        out = self.l2(out)\n\n        return out, last_attn_w\n    \n    @classmethod\n    def train_epoch(cls, net, criterion, trainloader, optimizer, epoch_idx, device='cuda', config=None, **kwargs):\n        \"\"\"This is the very basic training function for one epoch. Override this function when necessary\n            \n        Returns:\n            (float or dict): train_loss\n        \"\"\"\n        net.train()\n        train_loss = 0\n        pbar = tqdm(enumerate(trainloader), total=len(trainloader), disable=(kwargs.get(\"verbose\", 1) == 0))\n        batch_idx = 1\n        for batch_idx, (inputs) in pbar:\n            text = inputs['text']\n            targets = inputs['label'].to(net.device())\n            optimizer.zero_grad()\n            predicted = net(text)[0]\n            loss = criterion(predicted, targets)\n            loss.backward()\n            optimizer.step()\n            train_loss += loss.item()\n\n            pbar.set_description(\n                f\"epoch {epoch_idx + 1} iter {batch_idx}: train loss {loss.item():.5f}.\")\n        return train_loss / (batch_idx + 1)\n\n    @classmethod\n    def test_epoch(cls, net, criterion, testloader, scoring=None, epoch_idx=0, device='cuda', config=None, **kwargs):\n        \"\"\"This is the very basic evaluating function for one epoch. Override this function when necessary\n\n        Args:\n            scoring (Callable, optional): A scoring function that take in ``y_true`` and ``model_output``.\n              Usually, this is your evaluation metric, like accuracy.\n              If provided, this method return a dict that include both loss and score.\n              This scoring function should return the **sum** (set ``reduction=sum``) of the score of a batch.\n              The function signature must be ``scoring(y_true=, model_output=)``.\n              \n        Returns:\n            (float or dict): eval_loss\n        \"\"\"\n        net.eval()\n        test_loss = 0\n        test_score = 0\n        total = 0\n        with torch.inference_mode():\n            for batch_idx, (inputs) in enumerate(testloader):\n                text = inputs['text']\n                targets = inputs['label'].to(net.device())\n                predicted = net(text)[0]\n                loss = criterion(predicted, targets)\n                test_loss += loss.item()\n                if scoring is not None:\n                    score = scoring(model_output=predicted, y_true=targets)\n                    test_score += score\n                total += len(text)\n        if scoring is None:\n            return test_loss / (batch_idx + 1)\n        return {'loss': test_loss / (batch_idx + 1), 'score': test_score / total}\n\n    @classmethod\n    def predict_(cls, net, loader, device='cuda', config=None):\n        \"\"\"This is the very basic predicting function. Override this function when necessary\n            \n        Returns:\n            (list or dict): predict results\n        \"\"\"\n        net.to(device)\n        net.eval()\n        out = {}\n        with torch.inference_mode():\n            for batch_idx, (inputs) in enumerate(loader):\n                text = inputs['text']\n                predicted = net(text)[0]\n                preds_raw = predicted.max(1)[1]\n                for i in range(len(preds_raw)):\n                    out[text[i]] = idx2label[preds_raw[i]]\n        return out\n    @classmethod\n    def overfit_small_batch_(cls, net, criterion, dataset, optimizer, config=None):\n        \"\"\"This is a helper function to check if your model is working by checking if it can overfit a small dataset.\n        \n        Note:\n            It uses .train_epoch().\n            \n            This function will affect the model weights and all other training-related setting/parameters.\n         \n        \"\"\"\n        dataset = torch.utils.data.Subset(dataset, [0, 1, 2, 3])\n        loader = DataLoader(dataset, 2)\n        loss_history = []\n        for epoch in range(100):\n            train_loss = cls.train_epoch(net, criterion, loader, optimizer, epoch, config['device'], config, verbose=0)\n            loss_history.append(train_loss)\n        print(loss_history)\n        # del net_test\n        try:\n            last_loss = loss_history[-1].item()\n            if last_loss < 1e-5:\n                print(\n                    \"It looks like your model is working. Please double check the loss_history to see whether it is overfitting. Expected to be overfit.\")\n        except Exception:\n            pass\n        print(\"Please check the loss_history to see whether it is overfitting. Expected to be overfit.\")","metadata":{"id":"hz1iSFlLdSQL","execution":{"iopub.status.busy":"2022-07-04T13:00:47.837797Z","iopub.execute_input":"2022-07-04T13:00:47.838334Z","iopub.status.idle":"2022-07-04T13:00:47.867145Z","shell.execute_reply.started":"2022-07-04T13:00:47.838289Z","shell.execute_reply":"2022-07-04T13:00:47.866105Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader","metadata":{"execution":{"iopub.status.busy":"2022-07-04T13:00:47.870247Z","iopub.execute_input":"2022-07-04T13:00:47.870500Z","iopub.status.idle":"2022-07-04T13:00:47.882641Z","shell.execute_reply.started":"2022-07-04T13:00:47.870478Z","shell.execute_reply":"2022-07-04T13:00:47.881780Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"def accuarcy(model_output, y_true, reduction='sum'):\n    y_pred = model_output.max(1)[1]\n    out = (y_pred == y_true).float().sum().item()\n    return out\n  \ndef predict_directly(net, x):\n    out = net(x)\n    preds_raw = out[0].max(1)[1]\n    preds = {}\n    for i in range(len(preds_raw)):\n        preds[x[i]] = idx2label[preds_raw[i]]\n    return preds","metadata":{"id":"opude3_1nTdc","execution":{"iopub.status.busy":"2022-07-04T13:00:47.883940Z","iopub.execute_input":"2022-07-04T13:00:47.884209Z","iopub.status.idle":"2022-07-04T13:00:47.894633Z","shell.execute_reply.started":"2022-07-04T13:00:47.884186Z","shell.execute_reply":"2022-07-04T13:00:47.893704Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"markdown","source":"## Init Model","metadata":{"id":"dPuZrz3JhtLD"}},{"cell_type":"code","source":"# Model\nmodel = Bert(pretrain_model, tokenizer, 6, 512, freeze_pretrain=True)\n\n# Loss & Optimizer & Config\nmodel._config['max_epoch'] = 30\nmodel._lossfn = nn.CrossEntropyLoss()\nmodel._optimizer = torch.optim.Adam(model.parameters(), lr=5e-3, weight_decay=1e-3)\nmodel._lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(model._optimizer, model._config['max_epoch'])\n\n\n# Set GPU\ndevice = model.auto_gpu()","metadata":{"id":"afzvFoJpgfEh","outputId":"aa544728-755d-460b-f15a-5620d38b399d","execution":{"iopub.status.busy":"2022-07-04T13:27:18.743269Z","iopub.execute_input":"2022-07-04T13:27:18.743832Z","iopub.status.idle":"2022-07-04T13:27:18.814914Z","shell.execute_reply.started":"2022-07-04T13:27:18.743792Z","shell.execute_reply":"2022-07-04T13:27:18.810317Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"auto_gpu: using GPU (Tesla P100-PCIE-16GB)\n","output_type":"stream"}]},{"cell_type":"code","source":"# model.overfit_small_batch(dataset['train'])","metadata":{"execution":{"iopub.status.busy":"2022-07-04T13:27:18.931004Z","iopub.execute_input":"2022-07-04T13:27:18.931454Z","iopub.status.idle":"2022-07-04T13:27:18.937896Z","shell.execute_reply.started":"2022-07-04T13:27:18.931415Z","shell.execute_reply":"2022-07-04T13:27:18.936296Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"# FIT\nimport os\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nmodel.fit(dataset['train'], validation_data=dataset['validation'], batch_size=256, workers=4, scoring=accuarcy)","metadata":{"id":"8V8ED9D6hsT7","outputId":"aa3cef33-b100-4cb4-8c0f-65402d55d584","execution":{"iopub.status.busy":"2022-07-04T13:27:19.253194Z","iopub.execute_input":"2022-07-04T13:27:19.254074Z","iopub.status.idle":"2022-07-04T13:41:43.936856Z","shell.execute_reply.started":"2022-07-04T13:27:19.254041Z","shell.execute_reply":"2022-07-04T13:41:43.935636Z"},"trusted":true},"execution_count":50,"outputs":[{"name":"stderr","text":"epoch 1 iter 62: train loss 1.17994.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s] \n","output_type":"stream"},{"name":"stdout","text":"Epoch 0: Training loss: 2.968769864430503. Testing loss: {'loss': 1.1314822081327438, 'score': 0.5945}\n","output_type":"stream"},{"name":"stderr","text":"epoch 2 iter 62: train loss 0.95049.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1: Training loss: 1.0083359962417966. Testing loss: {'loss': 0.7658614906668663, 'score': 0.743}\n","output_type":"stream"},{"name":"stderr","text":"epoch 3 iter 62: train loss 0.78245.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 2: Training loss: 0.7675675418641832. Testing loss: {'loss': 0.5721869095563888, 'score': 0.805}\n","output_type":"stream"},{"name":"stderr","text":"epoch 4 iter 62: train loss 0.73573.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 3: Training loss: 0.6957168664251056. Testing loss: {'loss': 0.5782942697703838, 'score': 0.804}\n","output_type":"stream"},{"name":"stderr","text":"epoch 5 iter 62: train loss 0.59003.: 100%|██████████| 63/63 [00:24<00:00,  2.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 4: Training loss: 0.6467148075028072. Testing loss: {'loss': 0.5091140598058701, 'score': 0.825}\n","output_type":"stream"},{"name":"stderr","text":"epoch 6 iter 62: train loss 0.58871.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 5: Training loss: 0.6256072762466612. Testing loss: {'loss': 0.5118391069322824, 'score': 0.8265}\n","output_type":"stream"},{"name":"stderr","text":"epoch 7 iter 62: train loss 0.67627.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 6: Training loss: 0.6081361193505544. Testing loss: {'loss': 0.5101500227078796, 'score': 0.8275}\n","output_type":"stream"},{"name":"stderr","text":"epoch 8 iter 62: train loss 0.49524.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 7: Training loss: 0.6058357589774661. Testing loss: {'loss': 0.4782592851743102, 'score': 0.828}\n","output_type":"stream"},{"name":"stderr","text":"epoch 9 iter 62: train loss 0.66846.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 8: Training loss: 0.5796748797098795. Testing loss: {'loss': 0.4724682058393955, 'score': 0.836}\n","output_type":"stream"},{"name":"stderr","text":"epoch 10 iter 62: train loss 0.51720.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 9: Training loss: 0.5670536666635483. Testing loss: {'loss': 0.48946982476115225, 'score': 0.825}\n","output_type":"stream"},{"name":"stderr","text":"epoch 11 iter 62: train loss 0.61112.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 10: Training loss: 0.5675762097040812. Testing loss: {'loss': 0.49873720878362654, 'score': 0.822}\n","output_type":"stream"},{"name":"stderr","text":"epoch 12 iter 62: train loss 0.74963.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 11: Training loss: 0.5615776010922023. Testing loss: {'loss': 0.45264782138168813, 'score': 0.8425}\n","output_type":"stream"},{"name":"stderr","text":"epoch 13 iter 62: train loss 0.61633.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 12: Training loss: 0.542266077938534. Testing loss: {'loss': 0.4497188519611955, 'score': 0.8445}\n","output_type":"stream"},{"name":"stderr","text":"epoch 14 iter 62: train loss 0.40047.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 13: Training loss: 0.5318125935774001. Testing loss: {'loss': 0.40412843685224653, 'score': 0.8585}\n","output_type":"stream"},{"name":"stderr","text":"epoch 15 iter 62: train loss 0.66100.: 100%|██████████| 63/63 [00:24<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 14: Training loss: 0.5266223516729143. Testing loss: {'loss': 0.4389627384841442, 'score': 0.843}\n","output_type":"stream"},{"name":"stderr","text":"epoch 16 iter 62: train loss 0.45012.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 15: Training loss: 0.5180978935862345. Testing loss: {'loss': 0.39061033572256565, 'score': 0.859}\n","output_type":"stream"},{"name":"stderr","text":"epoch 17 iter 62: train loss 0.49442.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 16: Training loss: 0.4930305911435021. Testing loss: {'loss': 0.40567453517019747, 'score': 0.855}\n","output_type":"stream"},{"name":"stderr","text":"epoch 18 iter 62: train loss 0.60101.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 17: Training loss: 0.48425399736752583. Testing loss: {'loss': 0.4061247553490102, 'score': 0.8495}\n","output_type":"stream"},{"name":"stderr","text":"epoch 19 iter 62: train loss 0.43997.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 18: Training loss: 0.4756079377636077. Testing loss: {'loss': 0.3990077238082886, 'score': 0.8525}\n","output_type":"stream"},{"name":"stderr","text":"epoch 20 iter 62: train loss 0.43277.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 19: Training loss: 0.46248258295513334. Testing loss: {'loss': 0.3860270630531013, 'score': 0.8645}\n","output_type":"stream"},{"name":"stderr","text":"epoch 21 iter 62: train loss 0.38124.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 20: Training loss: 0.43711630692557685. Testing loss: {'loss': 0.38035083965957167, 'score': 0.862}\n","output_type":"stream"},{"name":"stderr","text":"epoch 22 iter 62: train loss 0.41824.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 21: Training loss: 0.4403748100712186. Testing loss: {'loss': 0.3576669943444431, 'score': 0.875}\n","output_type":"stream"},{"name":"stderr","text":"epoch 23 iter 62: train loss 0.53164.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 22: Training loss: 0.4274433080166105. Testing loss: {'loss': 0.3942038837224245, 'score': 0.853}\n","output_type":"stream"},{"name":"stderr","text":"epoch 24 iter 62: train loss 0.55066.: 100%|██████████| 63/63 [00:24<00:00,  2.54it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 23: Training loss: 0.419776846965154. Testing loss: {'loss': 0.37320304359868167, 'score': 0.8655}\n","output_type":"stream"},{"name":"stderr","text":"epoch 25 iter 62: train loss 0.30268.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 24: Training loss: 0.4050144595759256. Testing loss: {'loss': 0.3480694276113063, 'score': 0.8735}\n","output_type":"stream"},{"name":"stderr","text":"epoch 26 iter 62: train loss 0.34393.: 100%|██████████| 63/63 [00:24<00:00,  2.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 25: Training loss: 0.3893360618561033. Testing loss: {'loss': 0.3493854692615569, 'score': 0.867}\n","output_type":"stream"},{"name":"stderr","text":"epoch 27 iter 62: train loss 0.30534.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 26: Training loss: 0.37858667733177304. Testing loss: {'loss': 0.34079900888353587, 'score': 0.8735}\n","output_type":"stream"},{"name":"stderr","text":"epoch 28 iter 62: train loss 0.46630.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 27: Training loss: 0.37173253013974145. Testing loss: {'loss': 0.3381218536235392, 'score': 0.871}\n","output_type":"stream"},{"name":"stderr","text":"epoch 29 iter 62: train loss 0.29041.: 100%|██████████| 63/63 [00:24<00:00,  2.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 28: Training loss: 0.3706433465556493. Testing loss: {'loss': 0.33594237675517796, 'score': 0.8785}\n","output_type":"stream"},{"name":"stderr","text":"epoch 30 iter 62: train loss 0.42442.: 100%|██████████| 63/63 [00:24<00:00,  2.57it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 29: Training loss: 0.3670397727262406. Testing loss: {'loss': 0.33652917583845554, 'score': 0.875}\n","output_type":"stream"}]},{"cell_type":"code","source":"model.evaluate(dataset['test'], scoring=accuarcy)","metadata":{"id":"XLbquf5t4ORo","outputId":"20c89777-a111-4b66-8569-807608610263","execution":{"iopub.status.busy":"2022-07-04T13:45:56.867266Z","iopub.execute_input":"2022-07-04T13:45:56.867650Z","iopub.status.idle":"2022-07-04T13:46:00.880048Z","shell.execute_reply.started":"2022-07-04T13:45:56.867616Z","shell.execute_reply":"2022-07-04T13:46:00.878474Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"{'loss': 0.3481059001814574, 'score': 0.869}"},"metadata":{}}]},{"cell_type":"code","source":"idx2label = ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']\nx = ['I am sad', 'I am happy', 'i stopped feeling cold and began feeling hot', \n     'what the heck is this', \"i don't care what you do\", 'I love you 3000', 'I love you in every universe']\ny = [0, 1, 3, 4, 3, 2, 2]\npreds = predict_directly(model, x)\npreds","metadata":{"id":"ztw_tPoUjYR-","outputId":"1793f453-416e-4f5d-d98d-a6583ba894ac","execution":{"iopub.status.busy":"2022-07-04T13:51:36.512632Z","iopub.execute_input":"2022-07-04T13:51:36.513035Z","iopub.status.idle":"2022-07-04T13:51:36.536387Z","shell.execute_reply.started":"2022-07-04T13:51:36.513003Z","shell.execute_reply":"2022-07-04T13:51:36.535370Z"},"trusted":true},"execution_count":74,"outputs":[{"execution_count":74,"output_type":"execute_result","data":{"text/plain":"{'I am sad': 'sadness',\n 'I am happy': 'joy',\n 'i stopped feeling cold and began feeling hot': 'anger',\n 'what the heck is this': 'anger',\n \"i don't care what you do\": 'anger',\n 'I love you 3000': 'anger',\n 'I love you in every universe': 'sadness'}"},"metadata":{}}]},{"cell_type":"markdown","source":"Now we try to visualize which word contribute to the prediction.  \nThe higher attn weight tell us which token is important.  \nFor some unknown reason, the attn is lag by one word.  \nBut still it shows which is the important word.","metadata":{"id":"dmcbWG8EMtEf"}},{"cell_type":"code","source":"import seaborn as sns\nimport pandas as pd\nfrom matplotlib import pyplot as plt\n\n\npred, w = model(x)\nfor idx in range(0, len(x)):\n    print(y[idx], idx)\n    print(f\"Prediction: {idx2label[pred[idx].argmax().item()]}. Ground-Truth: {idx2label[y[idx]]}\")\n    print(f\"Prediction: {pred[idx].argmax().item()}. Ground-Truth: {y[idx]}\")\n    print(x[idx])\n    w_pure = w[idx][w[idx] !=0 ][1:].cpu().detach().numpy()\n    tokens_pure = tokenizer.tokenize(x[idx])\n    tokens = [f\"{i}_{tokens_pure[i]}\" for i in range(len(tokens_pure))]\n    full = list(zip(tokens, w_pure))\n    display(full)\n\n    out = []\n    out.append(list(full[0]))\n    for i in range(1, len(full)):\n        if full[i][0][:2] == '##':\n            out[-1][0] += full[i][0][2:]\n            out[-1][1] += full[i][1]\n        else:\n            out.append(list(full[i]))\n    sorted(out, key=lambda out: out[1], reverse=True)\n\n    \n    df = pd.DataFrame(w_pure, index=tokens_pure, columns=['attn_weight'])\n    plt.figure(figsize=(10,1.3))\n    fig = sns.heatmap(df.T, fmt=\"g\", cmap='viridis',xticklabels=tokens_pure)\n    fig.get_figure().savefig(\"out.png\",bbox_inches='tight', dpi=300) \n\n    # break","metadata":{"id":"nVtEgNmk8_5h","outputId":"7c9cb7dd-ad77-4b8f-c58c-9022c6af7369","execution":{"iopub.status.busy":"2022-07-04T13:51:36.845381Z","iopub.execute_input":"2022-07-04T13:51:36.845689Z","iopub.status.idle":"2022-07-04T13:51:39.699715Z","shell.execute_reply.started":"2022-07-04T13:51:36.845661Z","shell.execute_reply":"2022-07-04T13:51:39.698440Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"0 0\nPrediction: sadness. Ground-Truth: sadness\nPrediction: 0. Ground-Truth: 0\nI am sad\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.041227624), ('1_am', 0.69789195), ('2_sad', 0.12634642)]"},"metadata":{}},{"name":"stdout","text":"1 1\nPrediction: joy. Ground-Truth: joy\nPrediction: 1. Ground-Truth: 1\nI am happy\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.042612217), ('1_am', 0.6487813), ('2_happy', 0.13144785)]"},"metadata":{}},{"name":"stdout","text":"3 2\nPrediction: anger. Ground-Truth: anger\nPrediction: 3. Ground-Truth: 3\ni stopped feeling cold and began feeling hot\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.024852218),\n ('1_stopped', 0.027517088),\n ('2_feeling', 0.4777208),\n ('3_cold', 0.033971418),\n ('4_and', 0.015550555),\n ('5_began', 0.02346829),\n ('6_feeling', 0.2995329),\n ('7_hot', 0.050451487)]"},"metadata":{}},{"name":"stdout","text":"4 3\nPrediction: anger. Ground-Truth: fear\nPrediction: 3. Ground-Truth: 4\nwhat the heck is this\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_what', 0.06641406),\n ('1_the', 0.08870229),\n ('2_heck', 0.06578631),\n ('3_is', 0.13839799),\n ('4_this', 0.52843213)]"},"metadata":{}},{"name":"stdout","text":"3 4\nPrediction: anger. Ground-Truth: anger\nPrediction: 3. Ground-Truth: 3\ni don't care what you do\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.1186454),\n ('1_don', 0.10640065),\n (\"2_'\", 0.17390597),\n ('3_t', 0.04012368),\n ('4_care', 0.11071235),\n ('5_what', 0.14600022),\n ('6_you', 0.06022846),\n ('7_do', 0.032183893)]"},"metadata":{}},{"name":"stdout","text":"2 5\nPrediction: anger. Ground-Truth: love\nPrediction: 3. Ground-Truth: 2\nI love you 3000\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.13546982),\n ('1_love', 0.05649385),\n ('2_you', 0.5884026),\n ('3_3000', 0.12832159)]"},"metadata":{}},{"name":"stdout","text":"2 6\nPrediction: sadness. Ground-Truth: love\nPrediction: 0. Ground-Truth: 2\nI love you in every universe\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[('0_i', 0.18178302),\n ('1_love', 0.07297179),\n ('2_you', 0.07618167),\n ('3_in', 0.05108311),\n ('4_every', 0.048677504),\n ('5_universe', 0.42384768)]"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAhsAAABmCAYAAABiBFOLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAPCUlEQVR4nO3df7AdZX3H8ffnJoL8CD/EjHaAQuSXhUGCJGgVGITEUh1ALAyxVUKnNlqKSB2ooAymsQxgZnQcZQaizRRiKT9LTZlQmvIjiQTk5gcQAqUmMcjNSFXAxCYkuefcb//YDd1zufee3Zuz9+w5+bxmds7us/uc/T4Dd883z/PsriICMzMzs7L0tDsAMzMz625ONszMzKxUTjbMzMysVE42zMzMrFRONszMzKxUTjbMzMysVOPH4iTH3vfNrr6/duev92l3CKXacMG8dodQqk+edHa7QyjNCzdOancIpbpk6pPtDqFUT1z5oXaHUKpxj61sdwilWjxwr8bqXLVXj274nR3/3nVjdu48xiTZMDMzs/LsiP6G7ar9uFctHjMzMytoW9QatvdrUxzDcbJhZmbW4bYODDRsT2xTHMNxsmFmZtbhdkSlpmi8jZMNMzOzDrc1qv1zXu3ozMzMrKmtA3u1O4QROdkwMzPrcNvjHe0OYUS5H+olaUGeMjMzMxtb22LvhiUPSedIeknSOknXDLH/DEmrJNUkXThoX13SM+mysNm5ivRsnDDoROOAUwrUNzMzsxJsHyjWs5H+ht8CTAf6gF5JCyPihcxhvwAuBa4a4ivejIjJec/XNNmQdC3wNWAfSVt2FQM7ge5+tKSZmVkH2DqQrzcj41RgXURsAJB0F3A+8FayEREb030DQ31BEU2HUSLixoiYAMyNiAPSZUJEHBIR1+5uAGZmZrZ7tg3s1bDkcCjwSma7Ly3L652SVkh6StKnmh2cexglIq6VdChwRLZeRCwtEJyZmZm12OAJopJmAbMyRfMiopWjEUdExCZJ7wMelbQmItYPd3DuZEPSTcAMki6WelocgJMNMzOzNtpWbxxGSROLkZKLTcDhme3D0rJcImJT+rlB0uPAycDuJxvABcBxEbGjQB0zMzMrWc6hk6xe4BhJk0iSjBnAn+apKOlgYFtE7JD0buCjwLdGqpP71ldgA1DtG3nNzMz2QDsGxjcszUREDbgceBh4EbgnItZKmiPpPABJUyX1ARcBt0lam1b/A2CFpGeBx4CbBt3F8jZ57kb5HslwyTbgGUmPAG/1bkTEFU1bZWZmZqV5s168LyAiFgGLBpVdn1nvJRleGVxvOXBikXPlGUZZkX6uBJo+uMPMzMzGVp7ejHZqGl1E3D4WgZiZmdnobB9Fz8ZYKnI3yhqS4ZSszSQ9H38fEa+1MjAzMzPLp2uSDeAhklte70y3ZwD7Aq8C/wic29LIzMzMLJed9XHtDmFERZKNaRHxwcz2GkmrIuKDkj7b6sDMzMwsn+31as/ZKHLr6zhJp+7akDQV2JVK1VoalZmZmeW2oz6+YamaIhF9HpgvaX+SF7FtAT4vaT/gxjKCMzMzs+Zq3TKMkt5ve6KkA9PtzZnd97Q6MDMzM8un4+dsSPpsRPxI0lcGlQMQEd8uKTYzMzPLoVYvMiti7OXp2dgv/ZxQZiBmZmY2Ov21Du/ZiIjb0s+/Kz8cMzMzK6pe8Z6N3NFJOlbSI5KeT7c/IOm68kIzMzOzPOr1noalaopE9APgWqAfICKeI3mwl5mZmbXRQK2nYamaIre+7hsRT++aGJry8zXMzMzaLCrYm5FVJNn4jaSjSN+PIulC4JelRGVmZmb51dX8mDYqkmz8NTAPeL+kTcDPgT8rJSozMzPLr1btZCN3v0tEbIiIacBE4P0RcVpEvFxeaGZmZpZLXY1LDpLOkfSSpHWSrhli/xmSVkmqpaMZ2X0zJf0sXWY2O1eRV8yvB54ClqXL2rx1zczMrDwq2LMhaRxwCzAd6AN6JS2MiBcyh/0CuBS4alDddwHfAKaQTK1YmdZ9Y7jzFZlRcjxwG3AIMFfSekkPjNCQWZJWSFqxefGKAqcxMzOzIlRXw5LDqcC6dNRiJ3AXcH72gIjYmN55OjCo7h8BiyPi9TTBWAycM9LJiiQbdZLbXuvpiX+VLkOKiHkRMSUiphw4fUqB05iZmVkRqjcuORwKvJLZ7kvLSqlbZILoFmAN8G3gBxHxWoG6ZmZmVpLBwyiSZgGzMkXzImLemAaVUSTZ+AxwGnAZyavllwNLI+KRUiIzMzOzXAb3ZqSJxUjJxSbg8Mz2YWlZHpuAMwfVfXykCkXuRvlxRFwNfAFYRDJp5MG89c3MzKwcPbXGJYde4BhJkyTtRfJE8IU5T/cw8HFJB0s6GPh4WjZ8fDm/GEn3S1oHfBfYF7gEODhvfTMzMytH0TkbEVEDLidJEl4E7omItZLmSDoPQNJUSX3ARcBtktamdV8HvkmSsPQCc9KyYRUZRrkRWB0RQzZD0vSIWFzg+8zMzKwFck4KbRARi0hGKrJl12fWe0mGSIaqOx+Yn/dcRYZRVgyXaKRuzvtdZmZm1jqjGEYZU0V6Npqp9rNSzczMupQqmGBktTLZiBZ+l5mZmeU0mmGUsdTKZMPMzMzaoGcPSjY2tvC7zMzMLKeu6tmQ9BHgyGy9iLgj/fx0SyMzMzOzXKo4KTSryFtfFwBHAc+QvB8Fknkad7Q+LDMzM8urp1btaZNFejamAMdHRLVbZGZmtoep+jBKkbe+Pg+8t6xAzMzMbHS66Tkb7wZekPQ0sGNXYUSc1/KozMzMLLduGkaZXVYQZmZmNnpV7M3IKpJsfCIivpotkHQzsKS1IZmZmVkRVe/ZKDJnY/oQZX/cqkDMzMxsdFSPhqVqmvZsSPor4DLgKEnPZXZNAJaXFZiZmZnl09NfvQQjK88wyp3AQySvmL8mU/67Zu+vNzMzs/L11AbaHcKImiYbEbEZ2CypFhEvZ/dJWhARnystOjMzM2tKXTRn44TshqTxwCmtDcfMzMyK6ukfaFjykHSOpJckrZN0zRD795Z0d7r/p5KOTMuPlPSmpGfS5dZm58ozZ+Na4GvAPpK2ZHb1A/NytcjMzMxKo1qxR4hKGgfcQnLzRx/QK2lhRLyQOewvgDci4mhJM4CbgYvTfesjYnLe8zXt2YiIGyNiAjAXOCIN7Fzg0yRzOczMzKyNVBtoWHI4FVgXERsiYidwF3D+oGPOB25P1+8Dzpak0cRX5DkbG4ClwGEkL2P7MPAkcNZoTmxmZmatof7CL0c5FHgls90HfGi4YyKiJmkzcEi6b5Kk1cAW4LqIWDbSyYrM2bgCmAq8HBEfA04GflugvpmZmZWhNtCwSJolaUVmmdXCs/0S+P2IOBn4CnCnpANGqlCkZ2N7RGyXhKS9I+K/JB23O9GamZnZ7lN/4/PKI2IeI8+r3AQcntk+LC0b6pi+9KaQA4HX0re/70jPs1LSeuBYYMVwJyvSs9En6SDgX4HFkn4MvDxiDTMzMytff3/j0lwvcIykSZL2AmYACwcdsxCYma5fCDwaESFpYjrBFEnvA44hmWoxrNw9GxFxQbo6W9JjJBnOv+etb2ZmZiUpeDdKOgfjcuBhYBwwPyLWSpoDrIiIhcA/AAskrQNeJ0lIAM4A5kjqBwaALzZ7yGeRYZRskH75mpmZWVXk681oEBGLgEWDyq7PrG8HLhqi3v3A/UXONapkw8zMzKojdhZPNsaSkw0zM7NOV6s1P6aNnGyYmZl1uNi5s90hjMjJhpmZWYcb6K92z4aS22W7i6RZ6T3GXcnt61zd3DZw+zqd22dlKfKcjU7SyielVZHb17m6uW3g9nU6t89K0a3JhpmZmVWEkw0zMzMrVbcmG90+Juf2da5ubhu4fZ3O7bNSdOUEUTMzM6uObu3ZMDMzs4roymRD0vJ2x9AqkmZLuqrdcdjuk3SQpMvaHYflJ+l/Cx5/pqSPlBWPjY6vo+3XlclGRPiPvUNJ2tjuGEp0ELBHJRuS9rQHB54J+PpjNkhXJhtF/zVSNZK+Lum/Jf0EOC4tmyzpKUnPSXpA0sFp+eOSbpb0dFrn9LYGbyO5CThK0jOS5rY7mKIkXZL+//espAWSzpX0U0mrJf2npPekx81O9z9B8nrqiZLul9SbLh9tc1PeIulqSVek69+R9Gi6fpakf0rXb0jb/FSmjW9ru6QjgS8Cf5P+N67U36KkOZKuzGzfIOnLkuZKel7SGkkXp/vOlPRg5tjvS7p07KMevSLXUStfVyYbnUzSKcAMYDLwCWBquusO4KsR8QFgDfCNTLXxEXEqcOWg8k7063YHUKJrgPURMTkirm53MEVIOgG4DjgrIk4Cvgz8BPhwRJwM3AX8babK8cC0iPgM8F3gOxExFfgT4IdjGvzIlgG7koIpwP6S3pGWLQX2A55K27wU+Mv02Le1PSI2AreStHVyRCwbu2bkMh+4BEBSD8l1po/kWnMSMA2YK+n32hVgq4zyOmol2tO6ODvB6cADEbENQNJCkgveQRGxJD3mduDeTJ1/ST9XAkeOUZylSH+QrHrOAu6NiN8ARMTrkk4E7k5/nPYCfp45fmFEvJmuTwOOl7Rr3wGS9o+IKvRArgROkXQAsANYRZJ0nA5cAewEHswcOz1dP4zh215JEbFR0muSTgbeA6wGTgP+OSLqwP9IWkLyw7yljaG2wmiuo1Yi92x0hx3pZx0nkDZ2vgd8PyJOBL4AvDOzb2tmvYekF2ByuhxakUSDiOgnSRQuBZaT9HR8DDgaeBHoj/9/PkD272uktlfZD0na+uckPR3DqdH4+9Ap7bOKcrJRPUuBT0naR9IE4FySC/cbmTHgzwFLhvsCq6zfARPaHcQoPQpcJOkQAEnvAg4ENqX7Z45Q9z+AL+3akDS5pBhHaxlwFcnf3jKSeRerM0nGUIZre9X/Gz8AnEPSe/EwSXsvljRO0kTgDOBp4GWS3qi9JR0EnN2meEfL19GK8b+CKyYiVkm6G3gW+BXQm+6aCdwqaV9gA8m/TKyDRMRrkp6Q9DzwUCfN24iItZJuAJZIqpN0wc8G7pX0BkkyMmmY6lcAt0h6juSas5TkB70qlgFfB56MiK2StqdlI5nN0G3/N+A+SecDX6ravI2I2CnpMeC3EVGX9ADwhyTXmyCZe/IqgKR7gOdJen5Wtyvm0fB1tHr8BFEzsz1EOjF0FXBRRPys3fHYnsPDKGZmewBJxwPrgEecaNhYc8+GmZmZlco9G2ZmZlYqJxtmZmZWKicbZmZmVionG2ZmZlYqJxtmZmZWKicbZmZmVqr/AxDnIHCwALbJAAAAAElFTkSuQmCC\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x93.6 with 2 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":"","metadata":{"id":"0DECIPE5Ey9u"},"execution_count":null,"outputs":[]}]}